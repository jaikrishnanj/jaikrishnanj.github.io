<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Jaikrishnan&#39;s Homepage</title>
    <link>https://jaikrishnanj.github.io/post/</link>
      <atom:link href="https://jaikrishnanj.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 04 Jul 2019 11:12:00 -0400</lastBuildDate>
    <image>
      <url>https://jaikrishnanj.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://jaikrishnanj.github.io/post/</link>
    </image>
    
    <item>
      <title>What is the scientific approach?</title>
      <link>https://jaikrishnanj.github.io/post/2019-07-05-science/</link>
      <pubDate>Thu, 04 Jul 2019 11:12:00 -0400</pubDate>
      <guid>https://jaikrishnanj.github.io/post/2019-07-05-science/</guid>
      <description>&lt;p&gt;&lt;em&gt;&amp;ldquo;The function of the expert is not to be more right than other people, but to be wrong for more sophisticated reasons.&amp;quot;&lt;/em&gt; â€” &lt;strong&gt;David Butler&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this essay, I illustrate through the science of medicine what it means to take the &lt;em&gt;scientific approach&lt;/em&gt; to a discipline of human inquiry.  The central point I wish to make is that what we now call  &lt;em&gt;Science&lt;/em&gt; is nothing but the culmination of our base desire to ensure that our conclusions about the real world are &lt;em&gt;not wrong&lt;/em&gt;. Or, rather, is &lt;em&gt;as right&lt;/em&gt; as possibly can be within human limitations.  In any discipline of inquiry, we have a similar desire and is, &lt;em&gt;ipso facto&lt;/em&gt;, amenable to a scientific approach. Consequently, Science is dynamic, self-correcting and constantly improving. This essay is a small effort to show this in action with a concrete example.&lt;/p&gt;
&lt;h1 id=&#34;an-illustration-through-medicine&#34;&gt;An illustration through medicine&lt;/h1&gt;
&lt;p&gt;No discipline of science is plagued more by pseudoscience than medicine. Even in the realm of modern evidence-based medicine, there is still a lot of contention.  Mayo clinic found that one out of five second opinions to their clinics end up with an entirely different diagnosis!&lt;/p&gt;
&lt;p&gt;One main reason for the prevalence of pseudoscience in medicine is that our intuitive understanding of medicine is disastrously wrong. This leads to a tension between our naive perceptions and the conclusions reached by researchers after careful scrutiny. Common sense in India is that being in the cold increases the chances of catching a cold. It would be highly unusual for Indian parents to expose their child to the cold winter breeze. On the other hand, common sense in Norway is that fresh air, no matter how cold, is essential for good health! It is quite common for infants to be left outdoors to sleep even in sub-zero temperatures! These vast differences in cultural practices might have some underlying reasons but what it is can be understood only after rigorous study and analysis. On the other hand, it is also possible that some cultural differences are completely accidental and have no deeper underlying reason. Even in this case, it is only rigorous study and analysis that can give definitive answers. Failure to engage in this most fruitful endeavor has resulted in the vast number of &lt;em&gt;systems of medicine&lt;/em&gt;. There is no such thing as a &lt;em&gt;system of medicine&lt;/em&gt;! It is a myth perpetuated not always out of greed but most often out of failure of the practitioners of &amp;ldquo;alternative medicine&amp;rdquo; to subject their naive ideas to the razor-sharp tool of reason.&lt;/p&gt;
&lt;p&gt;One major aim of the field of medicine is the following:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Given an illness $I$, devise an effective treatment $T$ for $I$.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Before any progress can be made, we must first understand what it &lt;em&gt;means&lt;/em&gt; for a treatment to be effective. At this juncture, common sense and scientific rigour diverge. To most people, it is utterly &lt;em&gt;obvious&lt;/em&gt; what effective means! If the treatment $T$ &amp;ldquo;cures&amp;rdquo; the illness  $I$ then it is an effective treatment. With a little thought, we realise that this answer is nothing more than a restatement of the question! After further analysis, some might say: if there is an immediate improvement in the &lt;em&gt;symptoms&lt;/em&gt; of the illness $I$ then treatment $T$ is an effective treatment. There are a host of problems with this answer as well. For instance, common symptoms of most illnesses are pain and fatigue. It is by no means obvious that our subjective reporting of pain and fatigue is accurate enough to determine whether the symptoms have improved. This is immediately fixed by the following suggestion: why not observe whether the treatment $T$ works after administering it for several days at which point whether it has been effective or not is apparent? Another obstacle reveals itself. Many illnesses, even dangerous ones, often go away in due course without any intervention! A classic example is Hepatitis-B which gets cured in 99% of the cases with nothing but rest. If it takes one month of treatment with the famous medication Liv-52 for Hep-B to be cured, how exactly does one determine whether the treatment had any role at all? A more pertinent question, how do we know that Liv-52 is actually effective in the 1% of cases where treatment is necessary for a cure?&lt;/p&gt;
&lt;p&gt;Furthermore, there is the not completely understood &lt;em&gt;placebo effect&lt;/em&gt;. The very fact that one is aware that one is being treated has a profound effect on the course of the illness. Endorphins are released in the brain when one is aware that one is being treated. In fact, the very fact that one is &lt;em&gt;going&lt;/em&gt; to be treated results in a release of Endorphins. This has the immediate effect of relieving pain, increasing energy, etc. All this could give the impression that the treatment is very effective when in reality it is the Endorphins that are the cause of improvement. It is also possible that the placebo effect could have more profound effects. It is hopeful that one day, again through rigorous study and analysis, we might be able to properly and systematically exploit the placebo effect in conventional medicine. Nevertheless, there is substantial evidence that the placebo effect is not all-powerful. One should be very cautious of outrageous claims being made by practitioners of alternative medicine who claim organs can be regenerated and Cancer can be &amp;ldquo;canceled&amp;rdquo; through sheer will.  It is highly unlikely that the placebo effect will have any significance in treating Cancer or even Malaria.  Be that as it may, any &amp;ldquo;system of medicine&amp;rdquo; that fails to take into consideration the existence of the effect is bound to advocate cures that are not cures at all. Why is this a problem when the placebo effect is, after all, a &lt;em&gt;positive&lt;/em&gt; effect? Three problems spring to mind:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For any given illness, it makes sense to treat it with the absolute &lt;em&gt;best&lt;/em&gt; treatment we have at our disposal unless there are strong reasons not do so. For many illnesses, we have treatments that are demonstrably far better than placebo.&lt;/li&gt;
&lt;li&gt;Not all medicines sold by alternative medicine practitioners are safe. For instance, many Ayurvedic medicines have been found to have dangerous concentrations of heavy metals. Apart from this, many of the most potent poisons like Hemlock are derived from herbs.  As regulations for alternative medicine is a lot less restrictive than conventional medicine, what is the guarantee that a supposed harmless sugar pill does not contain some potentially dangerous drug? It is inadvisable to take a potentially dangerous treatment whose effects could be got by far safer treatments.&lt;/li&gt;
&lt;li&gt;Even for those illnesses for which conventional medicine has no answer, it is still a very good idea to subject alternative treatments available to scientific study. Why? Simply because an alternative medicine that can be demonstrated  to work becomes, well, medicine! Furthermore, while many alternative treatments have tremendous testimonials in their favour, rigorous study of such treatments show very contrasting results. Take for instance the case of a nurse who performed Reiki on Cancer patients to alleviate the nausea, fatigue and pain caused due to chemotherapy. It turns out that another nurse who had no knowledge of Reiki pretending to perform Reiki had the same effect on patients! The bigger lesson is the fact that a therapeutic massage had a reportedly better effect.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What we have done in the last few paragraphs is essentially engage ourselves in the ritual of Science. Centuries of concerted efforts by thousands of scientists who asked themselves some of the very same questions and performed tens of thousands of experiments to answer them have culminated in the central tool to test effectiveness of a treatment: &lt;em&gt;The double-blind, randomised, placebo-controlled trial&lt;/em&gt;.  Here is a simplified description of a double-blind RCT. To test the effectiveness of a medicine, we split the group of patients into two sets randomly. To one set, we give the medicine. To the other, we give a placebo, a pill that contains no active ingredient. Both groups are monitored for improvements and the medicine is considered to be effective only if it is demonstrably better than placebo in the trial. Sometimes, there is a third group which is given nothing but just monitored or the third group is given the current best treatment so that a comparison can be made. What does &lt;em&gt;double-blind&lt;/em&gt; mean? Well, both the patients as well as the researchers are unaware who gets the placebo and who gets the &amp;ldquo;real medicine&amp;rdquo;. The reason why the researchers are kept in the dark is to ensure that their biases do not influence the outcome of the experiments. Several experiments have conclusively demonstrated that a &amp;ldquo;single-blind&amp;rdquo; test is likely to be coloured by the biases of the researchers. It is an interesting exercise to devise experiments to detect such biases.&lt;/p&gt;
&lt;p&gt;Does the existence of the method of double-blind randomised control trials  mean that there is no way a better way testing effectiveness ? &lt;strong&gt;No!&lt;/strong&gt; It is quite possible that a better method can emerge after accumulation of more evidence. There are several scenarios in which it is impossible to devise a double-blind, randomised, placebo-controlled trial. For example, to determine whether something like the ever-controversial coconut oil is good or bad for health. Or whether exercise a better treatment for depression than medication. Many practitioners of alternative medicine argue that the existence of such scenarios and the possibility of the emergence of better methods is a death-knell  to double-blind, randomised, placebo-controlled trials. But this is needless nitpicking.  The inadequacy of the current &lt;em&gt;best tool&lt;/em&gt; does not mean that we abandon its use! In fact, we must always use the &lt;em&gt;best tool&lt;/em&gt; available at any given point if we want to decrease our chances of being &lt;em&gt;wrong&lt;/em&gt;. It seems to me that the alternative medicinal practitioners oppose double-blind studies because they &lt;em&gt;a priori&lt;/em&gt; believe that their treatment works. This could be either because of the cognitive biases, the same biases the RCTs were designed to counter, or sometimes outright greed. In fact, if any alternative medicine practitioner can give a compelling argument as to how a treatment can be effective and yet fail a controlled trial then I wager that the scientific community would be quite interested in the argument. What we must guard against is dogmatism. When eventually, researchers produce a better tool and provide compelling evidence that the new tool is indeed better, we must shift our allegiance. To be a scientist is to be a slave to the twin masters of reason and empirical evidence.&lt;/p&gt;
&lt;p&gt;The reader might  get the impression that the I am completely against research into alternative medicine. Absolutely not! Rather, research into alternative medicine must adhere to the same set of standards as conventional medicine. If evidence for an alternative treatment reaches the standards required  by Science then it actually becomes a medicine in the conventional sense! Many are not aware of this fact. This might prompt many to say that substantial research funding in medicine is to be diverted to Ayurveda, Siddha and Homeopathy. This is again taking an &amp;ldquo;unscientific&amp;rdquo; approach. The evidence against Homeopathy is so overwhelming that any further spending of money on it is completely unjustifiable. On the other hand, it is not productive to check each and every treatment of Ayurveda or Siddha or any other alternative medicinal system. On the database PubMed, there are already 83 papers studying the herbal preparation &lt;em&gt;Liv 52&lt;/em&gt; and a whopping &lt;em&gt;1105&lt;/em&gt; papers studying the herb &lt;em&gt;Ashwagandha&lt;/em&gt;! To the best of my knowledge, neither has been rigorously shown to be an effective treatment for any condition. This is all the more bizarre because Liv 52 has been consistently one of top selling medicines for decades. Himalaya, the company that manufactures it, has an annual revenue of around 2500 Crores out of which Liv 52 contributes around 300 Crores. The formulation was introduced 64 years ago and still there is no undisputed evidence that  it is effective! A more scientific approach might have resulted in clearer picture. In an ideal scenario, medical researchers should sit down with the prominent alternative medicinal doctors and first substantiate the treatments that are most likely to be effective. There is no doubt tremendous scope in exploiting the huge catalogue of herbs that have been passed on for generations. But it would be asinine to waste money checking whether sugar pills can cure diabetes!&lt;/p&gt;
&lt;p&gt;Coming to the issue of safety that was briefly discussed earlier. It is quite common for conventional medicines to be banned if some serious safety issue arises. The same standards should be applied to alternative medicines. As far as I am aware, the Ayurvedic practice of &amp;ldquo;Rakthamoksha&amp;rdquo; or bloodletting is not banned. Bloodletting is an effective treatment only for a handful of extremely rare illnesses but was used extensively in Ayurveda. This treatment has fallen out of favour but is still practiced by a few (as can been seen by a search on the Internet) and this needs to stop. In a similar vein, many Siddha treatments contain high-levels of Mercury which is dangerous. Many of the spinal manipulations that chiropractors engage could cause paralysis and sometimes even death! What is more disturbing is when chiropractors engage in such spinal manipulations in infants. There is absolutely no reason to allow such treatments until the practitioners can rigorously prove that the treatment is safe and effective. If one is sufficiently liberal to argue that ultimately it is one&amp;rsquo;s choice to take these treatments then there is no sense in banning even  conventional medicines that are dangerous. This double standard  is unacceptable.  An effective intermediary between the extremes could be statutory warnings (as seen in most conventional medicine covers or cigarettes) making it clear that the treatment has not been shown to be effective as per the current standards of medicinal research.&lt;/p&gt;
&lt;p&gt;The upshot of this prolonged discussion is to convince the reader that when we subject our naivetÃ© to the razor-sharp scalpel of reason, it is tattered to bits. But what emerges from this painful surgery is worth pursuing. Apart from utility, there is a paradoxical elegance and beauty in cold reason that kindles the heart of the most apathetic stoic. Many a scientist enamoured by the beauty of science has compared science to poetry and art. For what does a scientist do other than to understand the greatest work of art ever? &lt;em&gt;The universe!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The $g$-factor explained for mathematicians</title>
      <link>https://jaikrishnanj.github.io/post/2019-02-23-g/</link>
      <pubDate>Sat, 23 Feb 2019 11:12:00 -0400</pubDate>
      <guid>https://jaikrishnanj.github.io/post/2019-02-23-g/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: This is a brief summary of my understanding. I am neither a statistician nor a differential psychologist. As my understanding evolves, so will this article. In particular, I will add precise references to the statements I call Facts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Consider any task that requires &amp;ldquo;intelligence&amp;rdquo;. It could be solving some puzzles
involving geometry, abstract reasoning puzzles or even playing a complex video
game. Surely, all of us will accept that these tasks require some form of
intelligence. In fact, experience suggests that these tasks &lt;em&gt;do not&lt;/em&gt; involve the
&lt;em&gt;same type&lt;/em&gt; of intelligence. Furthermore, none of these tasks can be completed by pure intelligence. They involve other, but not necessarily &lt;em&gt;independent&lt;/em&gt;, factors such as concentration, motivation, work ethic, practice, ambition, will-to-win, discipline and host of other factors that seem to be special to the task at the hand. It is &lt;em&gt;a priori&lt;/em&gt; completely unclear that high ability in one task has any bearing on a different task. Of course, given that many of the factors (like concentration and motivation) listed above seem to have a role in &lt;em&gt;almost&lt;/em&gt; all intelligent tasks, it stands to reason that there will be &lt;em&gt;some&lt;/em&gt; correlation between ability in one task to the other. Indeed, this was observed by Spearman and has been subsequently replicated in tens of thousands of independent tests with only a handful of counter-results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact 1: The ability of an individual in one task positively correlates with ability in any other.  This is known as Spearman&amp;rsquo;s positive manifold. Sometimes the correlation is as low as 0.3 and sometimes as high as 0.97.  Typically it seems to be around 0.5-0.6.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given two individuals with different abilities in a task, the variation in
their abilities could occur from the variations in any one (or many) of the
factors that are needed for the task.  If $x_1, x_2, \dots, x_n$ are the factors that have a bearing on ones ability $A$ in a task $T$, one can as a first approximation write&lt;/p&gt;
&lt;p&gt;$$
A = c_1x_1 + c_2x_2 + \dots + c_n x_n
$$&lt;/p&gt;
&lt;p&gt;Here the coefficients $c_i$ are determined by the task $T$ whereas the values
of $x_i$ vary from individual to individual (the $x_i$ might not be constant for an individual and might depend on other factors like time of day, season, whether the individual is a good mood, etc)&lt;/p&gt;
&lt;p&gt;Spearman postulated the existence of one factor, which he named the $g$-factor to avoid any prejudice, that has a bearing on &lt;strong&gt;any&lt;/strong&gt;  cognitive task.  So we may write&lt;/p&gt;
&lt;p&gt;$$
A = c_g g + c_1 x_1 + \dots + c_n x_n
$$&lt;/p&gt;
&lt;p&gt;He proposed the existence of the $g$-factor as an explanation of the positive manifold.  He devised a method called factor analysis that takes an individual&amp;rsquo;s scores in a whole battery of cognitive tasks in which the scores are all positively correlated and distills the $g$-factor from the scores. Subsequent research has shown that the individual tasks themselves do not matter as long as there is a wide variety of them that involve reasoning, verbal ability, spatial reasoning, memory, processing, etc. as part of the battery.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact 2: The $g$-factor that one obtains by factor analysis does not depend on the choice of the battery of tasks as long as the battery involves a variety of tasks. As an extreme example, it has been found that the $g$-factor obtained from ability in a battery of video games has a correlation of 0.91 with the $g$-factor obtained from a standard IQ test!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Spearmen, and indeed no researcher in the field, view the $g$-factor as
completely capturing every aspect of intelligence ! There might be tasks for
which $c_g$ is very low. Indeed, this seems to be the case for many highly
intelligent activities like Chess and Go in which memory, training and
specialised factors overpower $g$.  There is also the matter of savants, i.e., individuals who possess extraordinary ability in only one task but whose IQ is often very low. One can view savants as possessing some unique feature in their brain that is well-adapted for one particular task. In fact, many savants are created after a head trauma.  It is also known from empirical studies that some aspects of factors like motivation and discipline are captured as a part of $g$.  It is interesting to note that originally Spearman viewed $g$ as capturing &amp;ldquo;intellectual energy&amp;rdquo;!  The term IQ gives the $g$-factor a bad reputation. Some assume without proper study that intelligence researchers claim all sorts of things that are simply untrue. This misunderstanding stems from prejudice and basic lack of academic integrity to engage with the literature before commenting.  Researchers most-definitely  do not claim that the $g$-factor captures all there is to intelligence. Indeed, musical ability, artistic ability, social ability etc. are not tested in an IQ test!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact 3: The $g$-factor is just one factor that is needed to score highly in a
given task. Typically the $g$-factor is believed to contribute somewhere between
30% and 80% of the variance between two individuals in a given test.  Some tests
are highly $g$-loaded (especially those that involve high amounts of abstract
reasoning) and others only mildly (those that involve a lot of memory). Tasks
that involve only reasoning seem to be the most $g$-loaded where the correlation
with the $g$-factor can be as high as a whopping 0.97! For spatial ability
tasks, the correlation is 0.91. It is possible, and I believe quite common, for
a person with IQ 130 to have significantly more achievement in academics than a
person with IQ 160 simply because he/she is more systematic and has a better work ethic or has cultivated those skills that are special to the subject, etc.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It is also clear from many attempts that there currently does not seem to be any way to significantly enhance one&amp;rsquo;s $g$-factor unless one has some a priori health issue like Iodine deficiency or depression or sleep issues, etc. In fact, the inter-test stability of the $g$-factor is  0.96, i.e., if one takes an IQ test today and then again six months later then the scores are very highly correlated. In fact, the stability of IQ over time is well-studied. One&amp;rsquo;s IQ at age 11 is correlated to one&amp;rsquo;s IQ at age 79 by 0.73!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact 4: The $g$-factor is largely stable over time and it is hitherto unknown whether it is possible to enhance it  consistently by practice or preparation. Of course, mild improvements (around 10 points) are possible by better schooling, better nutrition, exercise, cultivating discipline, good sleep, etc.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because the $g$-factor seems to capture something that seems useful in every cognitive task, it stands to reason that higher $g$-factors might help in academic achievement. Indeed there is strong evidence to suggest this. One&amp;rsquo;s IQ at age 11 is correlated by 0.8 to the performance in entrance exams 5 years later.  Also there is enough evidence to suggest that the $g$-factor is present in most academic achievement. This &lt;strong&gt;absolutely&lt;/strong&gt; does not mean that the variation in academic achievement is solely because of $g$!  Any complex academic task like publishing a paper is simply impossible without extensive knowledge, discipline and motivation no matter how intelligent one is! And many of the individual tasks in publishing a paper might have $c_g$ close to $0$. For instance, dealing with collaborators and physically performing the experiment properly do not seem to have meaningful contribution from $g$. Even things like knowing when to take a break to relax seem to be unrelated to the $g$-factor! But certain tasks seem to be highly $g$-loaded. Empirical evidence suggests that the current college system of attending lectures and tutorials, reading notes and books, solving assignments and giving exams is substantially $g$-loaded. Most people with IQ less than 100 struggle in such a system and ideally one requires an IQ of 115 to have achievement in academics (this applies to only US and European colleges as in Indian colleges memory plays a more substantial role and whose correlation with $g$ is only 0.63). It is currently unknown if in a different system, learning can be made more efficient for these people. But given that people with autism now earn PhD degrees because of radical and novel methods of learning in childhood, it betrays extreme bias to claim that high intelligence is necessary for academic success.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact 6: The current college system is heavily $g$-loaded and people with IQ &amp;lt; 100 are generally not high achievers in this system. It is hitherto unknown whether it is possible to devise alternate learning strategies to make the system more egalitarian. On the other hand, once the IQ scores cross a certain threshold, most variance in academic achievement in individuals do not stem from the $g$-factor but from a host of other factors like work ethics, knowledge and factors that are specialised to the subject.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Final fact: This should be obvious but most (including expert mathematicians) miss this point: correlation makes sense only when there is a full range of values in the variables being correlated. Most people who oppose the $g$-factor as measuring something meaningful are often serious academics.  They often have deep interactions only with other academics who are also likely to have a substantially higher IQ than average. Apart from this, such academics often have a range of specialised skills as well as high amount of specialised knowledge. When the range is so restricted, the correlations completely fail. For instance, there is no substantial correlation between IQ scores and performance in college for MIT students. This is because, the range of IQ of MIT students is substantially more restrictive than the general population. The handful of counter-studies against the $g$-factor make this trivial mistake.&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Links</title>
      <link>https://jaikrishnanj.github.io/post/2015-04-22-math/</link>
      <pubDate>Wed, 22 Apr 2015 11:12:00 -0400</pubDate>
      <guid>https://jaikrishnanj.github.io/post/2015-04-22-math/</guid>
      <description>&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
  </channel>
</rss>
